{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.\n",
    "### What is the main difference between the Euclidean distance metric and the Manhattan distance metric in KNN? How might this difference affect the performance of a KNN classifier or regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference between the Euclidean distance metric and the Manhattan distance metric in KNN lies in the way they measure the distance between two points. The key distinction is in the formula used to calculate the distance. Here's a brief comparison of the two distance metrics:\n",
    "\n",
    "### Euclidean Distance:\n",
    "\n",
    "- **Formula:** \\[ d_{\\text{euclidean}} = \\sqrt{\\sum_{i=1}^{n}(x_{2i} - x_{1i})^2} \\]\n",
    "- **Calculation:** It calculates the straight-line distance between two points in an n-dimensional space.\n",
    "- **Geometry:** Corresponds to the length of the shortest path between two points.\n",
    "- **Sensitivity:** Sensitive to variations in all dimensions.\n",
    "\n",
    "### Manhattan Distance:\n",
    "\n",
    "- **Formula:** \\[ d_{\\text{manhattan}} = \\sum_{i=1}^{n}|x_{2i} - x_{1i}| \\]\n",
    "- **Calculation:** It calculates the distance by summing the absolute differences between the coordinates along each dimension.\n",
    "- **Geometry:** Corresponds to the distance traveled along the axes of a grid or city blocks.\n",
    "- **Sensitivity:** Less sensitive to outliers in individual dimensions due to the use of absolute differences.\n",
    "\n",
    "### How the Difference Affects KNN:\n",
    "\n",
    "1. **Sensitivity to Dimensions:**\n",
    "   - **Euclidean:** Sensitive to variations in all dimensions equally. It considers both large and small differences.\n",
    "   - **Manhattan:** Less sensitive to outliers in individual dimensions due to the use of absolute differences.\n",
    "\n",
    "2. **Impact on Decision Boundaries:**\n",
    "   - **Euclidean:** Tends to create spherical decision boundaries in the feature space.\n",
    "   - **Manhattan:** Tends to create hyper-rectangular decision boundaries, aligning with the axes of the feature space.\n",
    "\n",
    "3. **Curse of Dimensionality:**\n",
    "   - **Euclidean:** More susceptible to the \"curse of dimensionality\" as the dimensionality increases.\n",
    "   - **Manhattan:** Can be more robust in high-dimensional spaces due to its nature of distance calculation.\n",
    "\n",
    "4. **Effect on Performance:**\n",
    "   - **Euclidean:** Can work well when features are correlated and contribute to the overall similarity in a balanced way.\n",
    "   - **Manhattan:** Can be more suitable when features contribute to similarity independently or when the features have different scales.\n",
    "\n",
    "5. **Application:**\n",
    "   - **Euclidean:** Often preferred when the relationships between features are more isotropic (similar in all directions).\n",
    "   - **Manhattan:** Might be preferred when features contribute independently or when the relationships are more anisotropic (differ in different directions).\n",
    "\n",
    "### Choosing Between Euclidean and Manhattan Distance:\n",
    "\n",
    "- **Experimentation:** The choice between Euclidean and Manhattan distance should be based on experimentation and cross-validation on your specific dataset.\n",
    "- **Data Characteristics:** Consider the characteristics of your data, the nature of the features, and the potential impact of outliers.\n",
    "\n",
    "In practice, it's common to try both distance metrics and choose the one that results in better performance for the specific problem at hand. The choice of distance metric is an important parameter to consider when using KNN, and it can significantly influence the algorithm's effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2.\n",
    "### How do you choose the optimal value of k for a KNN classifier or regressor? What techniques can be used to determine the optimal k value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the optimal value for the parameter K (number of neighbors) in a K-Nearest Neighbors (KNN) classifier or regressor is crucial for the performance of the algorithm. The choice of K can significantly impact the model's ability to generalize well to new, unseen data. Several techniques can be used to determine the optimal K value:\n",
    "\n",
    "### 1. **Grid Search:**\n",
    "   - **Method:** Perform a grid search over a range of K values and evaluate the model's performance using cross-validation.\n",
    "   - **Process:** Train and validate the model for each K value in the grid, and choose the K that results in the best performance.\n",
    "\n",
    "### 2. **Cross-Validation:**\n",
    "   - **Method:** Use k-fold cross-validation to assess the performance of the model for different values of K.\n",
    "   - **Process:** Split the training data into k folds, train the model on k-1 folds, and validate on the remaining fold. Repeat this process for different K values, and choose the K that gives the best cross-validated performance.\n",
    "\n",
    "### 3. **Elbow Method:**\n",
    "   - **Method:** Plot the model's performance (e.g., accuracy for classification or mean squared error for regression) as a function of K.\n",
    "   - **Process:** Look for the \"elbow\" point on the curve where the performance starts to stabilize. The K value corresponding to this point can be a good choice.\n",
    "\n",
    "### 4. **Leave-One-Out Cross-Validation (LOOCV):**\n",
    "   - **Method:** Use LOOCV, a special case of k-fold cross-validation where each fold consists of a single data point.\n",
    "   - **Process:** For each K value, train the model k times (k is the number of data points), leaving out one data point each time. Calculate the average performance and choose the K with the best overall performance.\n",
    "\n",
    "### 5. **Use Domain Knowledge:**\n",
    "   - **Method:** Leverage domain knowledge or prior understanding of the problem to choose an appropriate range for K.\n",
    "   - **Process:** Consider the characteristics of the data and the nature of the problem to narrow down the search space for the optimal K.\n",
    "\n",
    "### 6. **Iterative Training:**\n",
    "   - **Method:** Train the model iteratively for different K values and observe the performance.\n",
    "   - **Process:** Start with a small K value and gradually increase it, monitoring the model's performance. Stop when the performance no longer improves.\n",
    "\n",
    "### 7. **Randomized Search:**\n",
    "   - **Method:** Randomly sample K values from a predefined range and evaluate the model's performance.\n",
    "   - **Process:** Randomly select K values, train and validate the model, and choose the K that yields the best results.\n",
    "\n",
    "### 8. **Nested Cross-Validation:**\n",
    "   - **Method:** Implement nested cross-validation to avoid information leakage and obtain a more unbiased estimate of model performance.\n",
    "   - **Process:** The inner loop is used for hyperparameter tuning (choosing K), and the outer loop is used for assessing the model's performance.\n",
    "\n",
    "### Important Considerations:\n",
    "\n",
    "- **Data Characteristics:** The optimal K may depend on the characteristics of the data.\n",
    "- **Odd vs. Even:** For binary classification, consider choosing an odd value for K to avoid ties in majority voting.\n",
    "\n",
    "It's essential to note that the optimal K value may vary for different datasets and problems. Experimenting with multiple techniques and considering the specific requirements of the problem is a good practice. Additionally, always use an independent test set to validate the chosen K value after the hyperparameter tuning process to ensure unbiased evaluation on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3.\n",
    "### How does the choice of distance metric affect the performance of a KNN classifier or regressor? In what situations might you choose one distance metric over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choice of distance metric in a K-Nearest Neighbors (KNN) classifier or regressor significantly affects the performance of the algorithm. The distance metric determines how the similarity or dissimilarity between data points is calculated, and different metrics may be more suitable for specific types of data or problems. The two commonly used distance metrics are Euclidean distance and Manhattan distance (also known as L1 norm). Here's how the choice of distance metric can impact KNN performance and when to choose one over the other:\n",
    "\n",
    "### 1. **Euclidean Distance:**\n",
    "\n",
    "- **Calculation:** \\[ d_{\\text{euclidean}} = \\sqrt{\\sum_{i=1}^{n}(x_{2i} - x_{1i})^2} \\]\n",
    "- **Characteristics:**\n",
    "  - Measures straight-line distance between points in an n-dimensional space.\n",
    "  - Sensitive to differences in all dimensions.\n",
    "  - Assumes isotropic (similar in all directions) relationships between features.\n",
    "\n",
    "#### When to Choose Euclidean Distance:\n",
    "\n",
    "- **Isotropic Relationships:** Euclidean distance may be suitable when the relationships between features are isotropic, meaning they are similar in all directions.\n",
    "- **Similar Scales:** If features have similar scales, Euclidean distance might work well.\n",
    "- **Continuous Data:** Euclidean distance is often preferred for continuous data.\n",
    "\n",
    "### 2. **Manhattan Distance:**\n",
    "\n",
    "- **Calculation:** \\[ d_{\\text{manhattan}} = \\sum_{i=1}^{n}|x_{2i} - x_{1i}| \\]\n",
    "- **Characteristics:**\n",
    "  - Measures the distance traveled along the axes of a grid or city blocks.\n",
    "  - Less sensitive to outliers in individual dimensions due to the use of absolute differences.\n",
    "  - Assumes anisotropic (differ in different directions) relationships between features.\n",
    "\n",
    "#### When to Choose Manhattan Distance:\n",
    "\n",
    "- **Anisotropic Relationships:** Manhattan distance may be suitable when the relationships between features are anisotropic, meaning they differ in different directions.\n",
    "- **Different Scales:** If features have different scales, Manhattan distance might be more robust.\n",
    "- **Categorical Data:** Manhattan distance is often preferred for categorical or binary data.\n",
    "\n",
    "### Impact on KNN Performance:\n",
    "\n",
    "1. **Decision Boundaries:**\n",
    "   - **Euclidean:** Tends to create spherical decision boundaries in the feature space.\n",
    "   - **Manhattan:** Tends to create hyper-rectangular decision boundaries, aligning with the axes of the feature space.\n",
    "\n",
    "2. **Sensitivity to Outliers:**\n",
    "   - **Euclidean:** Sensitive to outliers as it involves squared differences.\n",
    "   - **Manhattan:** Less sensitive to outliers due to the use of absolute differences.\n",
    "\n",
    "3. **High-Dimensional Spaces:**\n",
    "   - **Euclidean:** More susceptible to the \"curse of dimensionality\" in high-dimensional spaces.\n",
    "   - **Manhattan:** Can be more robust in high-dimensional spaces due to its nature of distance calculation.\n",
    "\n",
    "4. **Feature Relationships:**\n",
    "   - **Euclidean:** Assumes isotropic relationships between features.\n",
    "   - **Manhattan:** Assumes anisotropic relationships between features.\n",
    "\n",
    "### Choosing Between Distance Metrics:\n",
    "\n",
    "- **Experimentation:** Experiment with both distance metrics and choose the one that results in better performance for your specific dataset and problem.\n",
    "- **Data Characteristics:** Consider the characteristics of your data, such as feature relationships, scales, and whether the data is continuous or categorical.\n",
    "\n",
    "In summary, the choice between Euclidean and Manhattan distance depends on the characteristics of the data and the nature of the problem. Experimenting with both distance metrics and considering the specific requirements of your task is essential to determine which metric works better for your KNN classifier or regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. \n",
    "### What are some common hyperparameters in KNN classifiers and regressors, and how do they affect the performance of the model? How might you go about tuning these hyperparameters to improve model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors (KNN) classifiers and regressors have hyperparameters that can significantly impact the performance of the model. Tuning these hyperparameters is essential to achieve the best results for a specific dataset and problem. Here are some common hyperparameters in KNN and their impact on model performance:\n",
    "\n",
    "### Common Hyperparameters in KNN:\n",
    "\n",
    "1. **Number of Neighbors (K):**\n",
    "   - **Hyperparameter:** \\( K \\)\n",
    "   - **Impact:** Determines the number of nearest neighbors to consider when making predictions.\n",
    "   - **Tuning:** Use techniques such as grid search, cross-validation, or iterative training to find the optimal value for \\( K \\).\n",
    "\n",
    "2. **Distance Metric:**\n",
    "   - **Hyperparameter:** Distance metric (e.g., Euclidean, Manhattan).\n",
    "   - **Impact:** Defines how the distance between data points is calculated.\n",
    "   - **Tuning:** Experiment with different distance metrics and choose the one that performs best for the specific dataset.\n",
    "\n",
    "3. **Weighting Scheme:**\n",
    "   - **Hyperparameter:** Weight function (e.g., uniform or distance-weighted).\n",
    "   - **Impact:** Determines how much influence each neighbor has on the prediction.\n",
    "   - **Tuning:** Evaluate the performance with different weighting schemes and select the one that yields better results.\n",
    "\n",
    "4. **Algorithm:**\n",
    "   - **Hyperparameter:** Algorithm used to compute nearest neighbors (e.g., brute-force, KD-tree, Ball tree).\n",
    "   - **Impact:** Affects the computational efficiency of finding nearest neighbors.\n",
    "   - **Tuning:** Depending on the dataset size and dimensionality, experiment with different algorithms and choose the one that provides a good balance between speed and accuracy.\n",
    "\n",
    "5. **Leaf Size (for KD-tree or Ball tree):**\n",
    "   - **Hyperparameter:** Leaf size in KD-tree or Ball tree construction.\n",
    "   - **Impact:** Influences the tree structure and search efficiency.\n",
    "   - **Tuning:** Experiment with different leaf sizes and choose the one that balances search efficiency and model accuracy.\n",
    "\n",
    "### Tuning Hyperparameters in KNN:\n",
    "\n",
    "1. **Grid Search:**\n",
    "   - **Method:** Systematically search a predefined grid of hyperparameter values.\n",
    "   - **Process:** Train and evaluate the model for each combination of hyperparameter values and choose the combination with the best performance.\n",
    "\n",
    "2. **Randomized Search:**\n",
    "   - **Method:** Randomly sample hyperparameter values from predefined distributions.\n",
    "   - **Process:** Train and evaluate the model for each set of randomly chosen hyperparameter values and select the combination with good performance.\n",
    "\n",
    "3. **Cross-Validation:**\n",
    "   - **Method:** Use cross-validation to assess the model's performance for different hyperparameter values.\n",
    "   - **Process:** Split the training data into multiple folds, train and validate the model for each set of hyperparameter values, and choose the values that result in the best cross-validated performance.\n",
    "\n",
    "4. **Iterative Training:**\n",
    "   - **Method:** Train the model iteratively with different hyperparameter values.\n",
    "   - **Process:** Start with a set of hyperparameter values, observe the performance, and iteratively refine the values until optimal performance is achieved.\n",
    "\n",
    "5. **Nested Cross-Validation:**\n",
    "   - **Method:** Implement nested cross-validation for unbiased hyperparameter tuning.\n",
    "   - **Process:** The inner loop is used for hyperparameter tuning, and the outer loop is used for assessing the model's performance.\n",
    "\n",
    "6. **Domain Knowledge:**\n",
    "   - **Method:** Leverage domain knowledge or prior understanding of the problem to guide hyperparameter tuning.\n",
    "   - **Process:** Adjust hyperparameter values based on insights into the data and the problem requirements.\n",
    "\n",
    "It's crucial to perform hyperparameter tuning judiciously, considering the specific characteristics of the dataset and the nature of the problem. Overfitting to the validation set during hyperparameter tuning should be avoided, and an independent test set should be used to evaluate the final model's performance. Experimentation and a thorough understanding of the impact of each hyperparameter are key to achieving the best results with KNN classifiers and regressors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5.\n",
    "### How does the size of the training set affect the performance of a KNN classifier or regressor? What techniques can be used to optimize the size of the training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the training set can significantly impact the performance of a K-Nearest Neighbors (KNN) classifier or regressor. The relationship between the training set size and model performance is influenced by various factors. Here's how the training set size affects KNN performance and some techniques to optimize the size of the training set:\n",
    "\n",
    "### Impact of Training Set Size:\n",
    "\n",
    "1. **Small Training Set:**\n",
    "   - **Issue:** With a small training set, the model may not capture the underlying patterns and relationships in the data effectively.\n",
    "   - **Challenge:** Proneness to overfitting, where the model might perform well on the training set but poorly on new, unseen data.\n",
    "\n",
    "2. **Large Training Set:**\n",
    "   - **Advantage:** A larger training set generally provides more diverse examples, helping the model generalize better to new data.\n",
    "   - **Challenge:** Increased computational complexity during prediction, as the algorithm needs to calculate distances to a larger number of training points.\n",
    "\n",
    "### Techniques to Optimize Training Set Size:\n",
    "\n",
    "1. **Cross-Validation:**\n",
    "   - **Method:** Use cross-validation to assess model performance across different training set sizes.\n",
    "   - **Process:** Divide the data into training and validation sets, and evaluate model performance for various training set sizes. Choose the size that balances bias and variance.\n",
    "\n",
    "2. **Learning Curves:**\n",
    "   - **Method:** Plot learning curves to visualize how model performance changes with varying training set sizes.\n",
    "   - **Process:** Train the model on subsets of the data with increasing sizes and plot performance metrics (e.g., accuracy, mean squared error) against the training set size. Identify the point of diminishing returns.\n",
    "\n",
    "3. **Incremental Training:**\n",
    "   - **Method:** Train the model incrementally on batches of data.\n",
    "   - **Process:** Start with a small subset of the data, train the model, and then gradually add more data in batches. Monitor how performance improves with each batch.\n",
    "\n",
    "4. **Data Augmentation:**\n",
    "   - **Method:** Augment the training set by creating new examples through transformations or perturbations of existing data.\n",
    "   - **Process:** Generate new samples by applying random transformations (e.g., rotations, flips, noise) to existing data. This can increase the effective size of the training set.\n",
    "\n",
    "5. **Bootstrap Aggregating (Bagging):**\n",
    "   - **Method:** Use ensemble techniques like bagging to train multiple models on different bootstrap samples of the training set.\n",
    "   - **Process:** Train several models on random subsets of the training data and combine their predictions. This can help mitigate overfitting and improve generalization.\n",
    "\n",
    "6. **Active Learning:**\n",
    "   - **Method:** Dynamically select the most informative samples for training.\n",
    "   - **Process:** Initially train the model on a small subset and iteratively choose additional samples from the data pool that are expected to provide the most information. This is particularly useful when labeling new data points is resource-intensive.\n",
    "\n",
    "7. **Data Quality Improvement:**\n",
    "   - **Method:** Focus on improving the quality of the existing training data.\n",
    "   - **Process:** Address issues such as data cleaning, outlier removal, and feature engineering to enhance the relevance and informativeness of the training set.\n",
    "\n",
    "### Considerations:\n",
    "\n",
    "- **Computational Resources:** The choice of training set size should consider the computational resources available for training and prediction.\n",
    "  \n",
    "- **Data Distribution:** Ensure that the training set is representative of the overall data distribution to avoid biases in the model.\n",
    "\n",
    "- **Validation and Test Sets:** Assess the performance on independent validation and test sets to ensure the model's generalization to new, unseen data.\n",
    "\n",
    "The optimal training set size is often a trade-off between having sufficient data for effective learning and avoiding excessive computational costs. Experimentation with different techniques and careful analysis of learning curves can guide the optimization of the training set size for KNN classifiers or regressors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6.\n",
    "### What are some potential drawbacks of using KNN as a classifier or regressor? How might you overcome these drawbacks to improve the performance of the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors (KNN) is a simple and intuitive algorithm, but it comes with its set of drawbacks. Understanding these drawbacks is essential for effectively using KNN as a classifier or regressor. Here are some potential drawbacks and strategies to overcome them:\n",
    "\n",
    "### Potential Drawbacks of KNN:\n",
    "\n",
    "1. **Computational Cost:**\n",
    "   - **Drawback:** Calculating distances for predictions can be computationally expensive, especially for large datasets and high-dimensional feature spaces.\n",
    "   - **Overcoming:** Use efficient data structures like KD-trees or Ball trees to speed up the search for nearest neighbors. Preprocess data or employ dimensionality reduction techniques to reduce computational cost.\n",
    "\n",
    "2. **Sensitivity to Outliers:**\n",
    "   - **Drawback:** KNN is sensitive to outliers since it relies on distance measures. Outliers can disproportionately influence predictions.\n",
    "   - **Overcoming:** Implement robust distance metrics or preprocessing techniques such as outlier removal or feature scaling. Consider using distance-weighted averaging to reduce the impact of outliers.\n",
    "\n",
    "3. **Choice of K:**\n",
    "   - **Drawback:** The performance of KNN is sensitive to the choice of the parameter K (number of neighbors). An inappropriate value of K can lead to overfitting or underfitting.\n",
    "   - **Overcoming:** Perform hyperparameter tuning using techniques like cross-validation or grid search to find the optimal K. Experiment with different values of K and choose the one that results in better generalization to unseen data.\n",
    "\n",
    "4. **Curse of Dimensionality:**\n",
    "   - **Drawback:** In high-dimensional spaces, the distance between data points becomes less meaningful, impacting the effectiveness of KNN. This is known as the \"curse of dimensionality.\"\n",
    "   - **Overcoming:** Apply dimensionality reduction techniques such as Principal Component Analysis (PCA) to reduce the number of dimensions. Feature selection or engineering may also help in focusing on relevant features.\n",
    "\n",
    "5. **Imbalanced Data:**\n",
    "   - **Drawback:** KNN may struggle with imbalanced datasets, where one class significantly outnumbers the others. The majority class can dominate the prediction.\n",
    "   - **Overcoming:** Use techniques like oversampling, undersampling, or incorporating class weights to address imbalanced datasets. Adjust the decision threshold if needed.\n",
    "\n",
    "6. **Feature Scaling:**\n",
    "   - **Drawback:** KNN is sensitive to the scale of features, and features with larger scales can dominate the distance calculations.\n",
    "   - **Overcoming:** Normalize or standardize features to ensure that all features contribute equally to distance calculations. Use appropriate feature scaling methods.\n",
    "\n",
    "7. **Memory Usage:**\n",
    "   - **Drawback:** For large datasets, KNN may require significant memory storage as the entire dataset needs to be stored for predictions.\n",
    "   - **Overcoming:** Consider using approximation techniques, subsampling, or distributed computing to handle large datasets more efficiently.\n",
    "\n",
    "### General Strategies to Improve KNN Performance:\n",
    "\n",
    "1. **Feature Engineering:**\n",
    "   - **Strategy:** Carefully select relevant features or engineer new features to improve the discriminatory power of the model.\n",
    "\n",
    "2. **Ensemble Methods:**\n",
    "   - **Strategy:** Combine multiple KNN models using ensemble methods like bagging or boosting to improve robustness and generalization.\n",
    "\n",
    "3. **Cross-Validation:**\n",
    "   - **Strategy:** Use cross-validation to assess the model's performance and tune hyperparameters, including the number of neighbors (K).\n",
    "\n",
    "4. **Distance Metric Selection:**\n",
    "   - **Strategy:** Experiment with different distance metrics (e.g., Euclidean, Manhattan) to find the one that performs best for the specific dataset.\n",
    "\n",
    "5. **Outlier Handling:**\n",
    "   - **Strategy:** Implement outlier detection and removal techniques to minimize the impact of outliers on predictions.\n",
    "\n",
    "6. **Data Preprocessing:**\n",
    "   - **Strategy:** Clean and preprocess data to address issues such as missing values, outliers, or irrelevant features.\n",
    "\n",
    "7. **Parallelization:**\n",
    "   - **Strategy:** Use parallel or distributed computing to speed up calculations, especially for large datasets.\n",
    "\n",
    "By addressing these drawbacks and implementing appropriate strategies, it's possible to improve the performance of a KNN classifier or regressor and make it more effective for various types of data and problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completed_21th_April_Assignment:\n",
    "## ______________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
